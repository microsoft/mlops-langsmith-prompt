{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://python.langchain.com/docs/integrations/chat/azure_chat_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.11\n",
      "  Using cached langchain-0.1.11-py3-none-any.whl (807 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in .\\lib\\site-packages (from langchain==0.1.11) (2.6.3)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached SQLAlchemy-2.0.28-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\lib\\site-packages (from langchain==0.1.11) (2.31.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Using cached langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.29\n",
      "  Using cached langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.25\n",
      "  Using cached langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
      "Requirement already satisfied: numpy<2,>=1 in .\\lib\\site-packages (from langchain==0.1.11) (1.26.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\lib\\site-packages (from langchain==0.1.11) (6.0.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in .\\lib\\site-packages (from langchain==0.1.11) (8.2.3)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.8/60.8 KB 1.6 MB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.11) (2.4)\n",
      "Collecting anyio<5,>=3\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in .\\lib\\site-packages (from langchain-core<0.2,>=0.1.29->langchain==0.1.11) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.11) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in .\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.11) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in .\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.11) (4.10.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in .\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.11) (2.16.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (2.2.1)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-3.0.3-cp39-cp39-win_amd64.whl (290 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain==0.1.11) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain==0.1.11) (1.2.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, multidict, marshmallow, jsonpatch, greenlet, frozenlist, attrs, async-timeout, anyio, yarl, typing-inspect, SQLAlchemy, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 anyio-4.3.0 async-timeout-4.0.3 attrs-23.2.0 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\dev\\git\\langchain\\langchain\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai==0.0.8\n",
      "  Using cached langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in .\\lib\\site-packages (from langchain-openai==0.0.8) (0.1.30)\n",
      "Collecting openai<2.0.0,>=1.10.0\n",
      "  Using cached openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "Collecting tiktoken<1,>=0.5.2\n",
      "  Using cached tiktoken-0.6.0-cp39-cp39-win_amd64.whl (798 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.6.3)\n",
      "Requirement already satisfied: anyio<5,>=3 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (1.33)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.31.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (6.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (0.1.23)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.25.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in .\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: sniffio in .\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in .\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.66.2)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2023.12.25-cp39-cp39-win_amd64.whl (269 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in .\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.6)\n",
      "Requirement already satisfied: certifi in .\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in .\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.9.15)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in .\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in .\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (0.6.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.3.2)\n",
      "Requirement already satisfied: colorama in .\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.4.6)\n",
      "Installing collected packages: regex, distro, tiktoken, openai, langchain-openai\n",
      "Successfully installed distro-1.9.0 langchain-openai-0.0.8 openai-1.13.3 regex-2023.12.25 tiktoken-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\dev\\git\\langchain\\langchain\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai==0.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"1a0124422b6749279eb242b465a336fd\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://mypromptflowopenai.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-12-01-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_deployment=\"gpt-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = HumanMessage(\n",
    "    content=\"Translate this sentence from English to French. I love programming.\"\n",
    ")\n",
    "llm([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith, as of my last update in April 2023, is a tool designed to enhance language learning and writing assistance. However, if your inquiry pertains to how Langsmith or similar language technology tools can assist in testing, especially in the context of language learning, software development, or academic testing, here are some generalized ways such tools can be beneficial:\\n\\n### 1. **Automated Evaluation and Feedback**\\nLangsmith-like tools can be utilized to automatically assess written responses in tests. They can evaluate grammar, spelling, syntax, and even the cohesiveness of arguments in essays or written responses. This immediate feedback can be valuable for both learners and educators in understanding areas of improvement.\\n\\n### 2. **Customized Testing Material**\\nSuch tools can assist in generating or customizing testing materials based on the proficiency levels of the learners. By analyzing the common mistakes or areas where learners struggle, Langsmith could theoretically help in creating more targeted testing materials that address these specific areas.\\n\\n### 3. **Language Proficiency Assessment**\\nIn the context of language learning, tools like Langsmith could be instrumental in assessing language proficiency levels. They can analyze writing samples or spoken language inputs to evaluate a learner's proficiency level, thereby helping educators tailor the testing and learning materials accordingly.\\n\\n### 4. **Practice and Reinforcement**\\nLangsmith and similar tools could provide practice exercises and simulate testing environments for learners. This not only helps in reinforcing the learning material but also in reducing test anxiety as students become more accustomed to the format and expectations of the tests.\\n\\n### 5. **Plagiarism Detection**\\nIn academic testing or in the submission of written assignments, tools integrated with plagiarism detection features can ensure the integrity of the submissions. While not directly mentioned as a feature of Langsmith, language technology tools often include or can be integrated with plagiarism detection capabilities.\\n\\n### 6. **Accessibility and Inclusivity**\\nLanguage technology tools can offer features that make tests more accessible to learners with disabilities. For example, text-to-speech, speech-to-text, or language simplification features can make tests more inclusive, catering to a broader range of learning needs and preferences.\\n\\n### 7. **Data-Driven Insights for Educators**\\nBy analyzing the results and patterns in responses, Langsmith-like tools can provide educators with insights into the effectiveness of their teaching methods and the areas where students struggle the most. This data-driven approach can inform adjustments in teaching strategies and testing methods.\\n\\nIt's important to note that while Langsmith may not directly offer all these features, language technology tools and platforms are increasingly incorporating such functionalities to support both learning and assessment processes. Always check the latest capabilities of specific tools to understand how they can meet your testing needs.\")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith is an AI-driven tool that can significantly enhance the efficiency and effectiveness of testing processes in various ways. While I don't have specific, up-to-date details about Langsmith's latest features as of my last knowledge update in April 2023, I can outline several general ways an AI tool like Langsmith could be beneficial in a testing context, assuming it is designed to assist with coding, documentation, and possibly testing processes:\\n\\n1. **Automated Test Generation**: Langsmith could potentially help generate test cases based on the application's requirements or user stories. By analyzing the specifications, it could suggest a comprehensive set of test scenarios, ensuring that both common and edge cases are covered, thus improving test coverage and the likelihood of identifying bugs.\\n\\n2. **Code Quality Analysis**: By analyzing code, Langsmith might help identify potential issues or anti-patterns that could lead to bugs, thereby allowing developers to address these issues before they proceed to the testing phase. This preemptive action can save time and resources by reducing the number of iterations needed in the testing cycle.\\n\\n3. **Documentation Testing**: Langsmith could assist in validating technical documentation against the actual behavior of the software. It might automate the process of ensuring that code examples, API calls, and other technical instructions in the documentation work as described, thus ensuring accuracy and consistency.\\n\\n4. **Natural Language Processing (NLP) for Test Case Description**: The tool could employ NLP to understand test cases written in natural language, making it easier for non-technical stakeholders to write or review test cases. This feature would bridge the gap between technical and non-technical team members, facilitating better communication and understanding of testing requirements.\\n\\n5. **Bug Reporting and Documentation**: Langsmith could streamline the bug reporting process by automatically generating detailed bug reports when a test fails. This documentation could include steps to reproduce the issue, logs, screenshots, and other relevant information, making it easier for developers to diagnose and fix the problem.\\n\\n6. **Integration with Development and Testing Tools**: If Langsmith can integrate with popular development and testing tools, it could automate various aspects of the testing workflow, such as triggering specific tests when new code is committed, updating test cases when requirements change, or even suggesting changes to tests based on code modifications.\\n\\n7. **Learning from Past Projects**: An AI tool like Langsmith could learn from previous testing cycles and projects, identifying patterns or common issues in similar applications. This knowledge could be used to predict potential problem areas in new projects, allowing testers to focus their efforts more effectively.\\n\\nIt's important to note that the effectiveness of Langsmith in these areas would depend on its specific capabilities, the quality of its AI models, and how well it has been trained on relevant data. Always consider consulting the latest documentation or support resources for the most current information on its features and how best to leverage them for your testing needs.\")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangSmith, while not a specific product or service I am familiar with as of my last update in 2023, appears to be conceptualized as a tool or platform that could assist in various facets of software development, including testing. Assuming LangSmith is designed with capabilities to aid in the software testing process, here's how it could potentially help:\\n\\n### 1. **Automated Test Generation**\\nLangSmith could leverage AI to understand the application's functionality and automatically generate test cases, reducing the manual effort required in test creation. This could include unit tests, integration tests, and even system tests, depending on the level of sophistication and understanding of the software's architecture.\\n\\n### 2. **Natural Language Processing (NLP) for Test Scripts**\\nBy utilizing NLP, LangSmith could allow testers and developers to write test cases in plain English or any other supported natural language. This would make test creation more accessible to non-technical stakeholders and facilitate better collaboration between technical and non-technical team members.\\n\\n### 3. **Code Quality Analysis**\\nLangSmith could analyze source code to identify potential bugs, vulnerabilities, or areas for optimization. This preemptive analysis helps in reducing the number of issues found during later stages of testing, thus improving the overall quality of the software.\\n\\n### 4. **AI-Powered Debugging Assistance**\\nIn the event of test failures, LangSmith could assist in identifying the root causes by analyzing the code, test scripts, and error logs. By providing insights or even potential fixes, it could significantly reduce the time developers spend on debugging.\\n\\n### 5. **Enhanced Test Coverage Insights**\\nThrough AI, LangSmith could analyze existing test cases against the software's features and functionalities to identify gaps in test coverage. This would help ensure that all aspects of the application are thoroughly tested, reducing the risk of defects slipping through to production.\\n\\n### 6. **Performance Testing**\\nLangSmith could assist in performance testing by simulating user interactions and measuring the application's responsiveness. It could also use historical data to predict potential performance bottlenecks under various conditions.\\n\\n### 7. **Security Testing**\\nIf equipped with security testing features, LangSmith could automatically scan code for vulnerabilities and compliance issues. This would be especially beneficial in early stages of development, fostering a secure-by-design approach.\\n\\n### 8. **Continuous Integration/Continuous Deployment (CI/CD) Integration**\\nLangSmith could integrate with CI/CD pipelines to automate the execution of test suites upon each code commit or at scheduled intervals. This ensures immediate feedback on the impact of changes, facilitating agile development practices.\\n\\n### 9. **Collaboration and Reporting Tools**\\nBy providing detailed reports and analytics on testing outcomes, LangSmith could facilitate better communication among team members. Its collaboration tools could allow for real-time feedback and quick resolution of issues identified during testing.\\n\\n### 10. **Learning and Adaptation**\\nOver time, LangSmith could learn from the outcomes of past testing cycles, adapting its testing strategies to be more effective and efficient. This continuous improvement could lead to more robust and reliable software over successive releases.\\n\\nIn summary, while the specific capabilities of LangSmith would depend on its actual implementation and design, the potential for such a tool to transform and enhance the software testing process is significant. By automating routine tasks, providing insights through AI and machine learning, and fostering better collaboration among team members, LangSmith could become an invaluable asset in the quest for high-quality, reliable software.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langsmith in .\\lib\\site-packages (0.1.23)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\lib\\site-packages (from langsmith) (3.9.15)\n",
      "Requirement already satisfied: pydantic<3,>=1 in .\\lib\\site-packages (from langsmith) (2.6.3)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\lib\\site-packages (from langsmith) (2.31.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in .\\lib\\site-packages (from pydantic<3,>=1->langsmith) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in .\\lib\\site-packages (from pydantic<3,>=1->langsmith) (4.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in .\\lib\\site-packages (from pydantic<3,>=1->langsmith) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\lib\\site-packages (from requests<3,>=2->langsmith) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\lib\\site-packages (from requests<3,>=2->langsmith) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\lib\\site-packages (from requests<3,>=2->langsmith) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\lib\\site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\dev\\git\\langchain\\langchain\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "project_name = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log a trace via REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.smith.langchain.com/cookbook/tracing-examples/rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [202]>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "import requests\n",
    "\n",
    "_LANGSMITH_API_KEY = os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "\n",
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "res = requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"id\": run_id,\n",
    "        \"name\": \"MyFirstRun\",\n",
    "        \"run_type\": \"chain\",\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"inputs\": {\"text\": \"Foo\"},\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [202]>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.patch(\n",
    "    f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "    json={\n",
    "        \"outputs\": {\"my_output\": \"Bar\"},\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex chain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import datetime\n",
    "import uuid\n",
    "import requests\n",
    "\n",
    "_LANGSMITH_API_KEY = os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"id\": run_id,\n",
    "        \"name\": \"MySecondRun\",\n",
    "        \"run_type\": \"chain\",\n",
    "        \"inputs\": {\"text\": \"Foo\"},\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"session_name\": project_name,\n",
    "        \"tags\": [\"langsmith\", \"rest\", \"my-example\"],\n",
    "        \"extra\": {\n",
    "            \"metadata\": {\"my_key\": \"My value\"},\n",
    "            \"runtime\": {\n",
    "                \"platform\": platform.platform(),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")\n",
    "# ... do some work ...\n",
    "events = []\n",
    "# Events like new tokens and retries can be added\n",
    "events.append({\"event_name\": \"retry\", \"reason\": \"never gonna give you up\"})\n",
    "events.append({\"event_name\": \"new_token\", \"value\": \"foo\"})\n",
    "\n",
    "res = requests.patch(\n",
    "    f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "    json={\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"outputs\": {\"generated\": \"Bar\"},\n",
    "        \"events\": events,\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"id\": run_id,\n",
    "        \"name\": \"MySecondRun\",\n",
    "        \"run_type\": \"chain\",\n",
    "        \"inputs\": {\"text\": \"Foo\"},\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"session_name\": project_name,\n",
    "        \"tags\": [\"langsmith\", \"rest\", \"my-example\"],\n",
    "        \"extra\": {\n",
    "            \"metadata\": {\"my_key\": \"My value\"},\n",
    "            \"runtime\": {\n",
    "                \"platform\": platform.platform(),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")\n",
    "# ... do some work ...\n",
    "events = []\n",
    "# Events like new tokens and retries can be added\n",
    "events.append({\"event_name\": \"retry\", \"reason\": \"never gonna give you up\"})\n",
    "events.append({\"event_name\": \"new_token\", \"value\": \"foo\"})\n",
    "\n",
    "res = requests.patch(\n",
    "    f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "    json={\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"outputs\": {\"generated\": \"Bar\"},\n",
    "        \"events\": events,\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [202]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = str(uuid.uuid4())\n",
    "requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"id\": run_id,\n",
    "        \"name\": \"MyChatModelRun\",\n",
    "        \"run_type\": \"llm\",\n",
    "        \"inputs\": {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in SF like?\"}],\n",
    "            # Optional\n",
    "            \"model\": \"text-davinci-003\",\n",
    "            \"functions\": [\n",
    "                {\n",
    "                    \"name\": \"get_current_weather\",\n",
    "                    \"description\": \"Get the current weather in a given location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                            },\n",
    "                            \"unit\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\"location\"],\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "            # You can add other invocation paramers as k-v pairs\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"session_name\": project_name,\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")\n",
    "\n",
    "requests.patch(\n",
    "    f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "    json={\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"outputs\": {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"index\": 0,\n",
    "                    \"message\": {\n",
    "                        \"role\": \"assistant\",\n",
    "                        # Content is whatever string response the\n",
    "                        # model generates\n",
    "                        \"content\": \"Mostly cloudy.\",\n",
    "                        # Function call is the function invocation and arguments\n",
    "                        # as a string\n",
    "                        \"function_call\": {\n",
    "                            \"name\": \"get_current_weather\",\n",
    "                            \"arguments\": '{\\n\"location\": \"San Francisco, CA\"\\n}',\n",
    "                        },\n",
    "                    },\n",
    "                    \"finish_reason\": \"function_call\",\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [202]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = str(uuid.uuid4())\n",
    "requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"id\": run_id,\n",
    "        \"name\": \"MyLLMRun\",\n",
    "        \"run_type\": \"llm\",\n",
    "        \"inputs\": {\n",
    "            \"prompt\": \"Hi there!\",\n",
    "            # Optional: model or engine name, and other invocation params\n",
    "            \"engine\": \"text-davinci-003\",\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"session_name\": project_name,\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")\n",
    "\n",
    "requests.patch(\n",
    "    f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "    json={\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"outputs\": {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"text\": \"\\nMy name is Polly and I'm excited to talk to you!\",\n",
    "                    \"index\": 0,\n",
    "                    \"logprobs\": None,\n",
    "                    \"finish_reason\": \"stop\",\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesting Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class RunLogger:\n",
    "    def post_run(\n",
    "        self, data: dict, name: str, run_id: str, parent_run_id: Optional[str] = None\n",
    "    ) -> None:\n",
    "        requests.post(\n",
    "            \"https://api.smith.langchain.com/runs\",\n",
    "            json={\n",
    "                \"id\": run_id,\n",
    "                \"name\": name,\n",
    "                \"run_type\": \"chain\",\n",
    "                \"parent_run_id\": parent_run_id,\n",
    "                \"inputs\": data,\n",
    "                \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "                \"session_name\": project_name,\n",
    "            },\n",
    "            headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    "        )\n",
    "\n",
    "    def patch_run(\n",
    "        self, run_id: str, output: Optional[dict] = None, error: Optional[str] = None\n",
    "    ) -> None:\n",
    "        requests.patch(\n",
    "            f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "            json={\n",
    "                \"error\": error,\n",
    "                \"outputs\": output,\n",
    "                \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "            },\n",
    "            headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = RunLogger()\n",
    "\n",
    "\n",
    "def fibonacci(n: int, depth: int = 0, parent_run_id: Optional[str] = None) -> int:\n",
    "    run_id = str(uuid.uuid4())\n",
    "    logger.post_run(\n",
    "        {\"n\": n}, f\"fibonacci_recursive\", run_id, parent_run_id=parent_run_id\n",
    "    )\n",
    "    try:\n",
    "        if n <= 1:\n",
    "            result = n\n",
    "        else:\n",
    "            result = fibonacci(n - 1, depth + 1, parent_run_id=run_id) + fibonacci(\n",
    "                n - 2, depth + 1, parent_run_id=run_id\n",
    "            )\n",
    "        logger.patch_run(run_id, output={\"result\": result})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.patch_run(run_id, error=str(e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fibonacci(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n: int, depth: int = 0, parent_run_id: Optional[str] = None) -> int:\n",
    "    run_id = str(uuid.uuid4())\n",
    "    logger.post_run(\n",
    "        {\"n\": n}, f\"fibonacci_recursive\", run_id, parent_run_id=parent_run_id\n",
    "    )\n",
    "    try:\n",
    "        if n < 0:\n",
    "            raise ValueError(\"NEGATIVE NUMER NOT ALLOWED\")\n",
    "        if n <= 1:\n",
    "            result = n\n",
    "        else:\n",
    "            result = fibonacci(n - 1, depth + 1, parent_run_id=run_id) + fibonacci(\n",
    "                n - 2, depth + 1, parent_run_id=run_id\n",
    "            )\n",
    "        logger.patch_run(run_id, output={\"result\": result})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.patch_run(run_id, error=str(e))\n",
    "        raise\n",
    "\n",
    "\n",
    "# We will show what the trace looks like with an error\n",
    "try:\n",
    "    fibonacci(2.3)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [202]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"name\": \"MyLLMRun\",\n",
    "        \"run_type\": \"llm\",\n",
    "        \"inputs\": {\n",
    "            \"prompt\": \"Hi there!\",\n",
    "            # Optional: model or engine name, and other invocation params\n",
    "            \"engine\": \"text-davinci-003\",\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"text\": \"\\nMy name is Polly and I'm excited to talk to you!\",\n",
    "                    \"index\": 0,\n",
    "                    \"logprobs\": None,\n",
    "                    \"finish_reason\": \"stop\",\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        \"session_name\": project_name,\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "    },\n",
    "    headers={\"x-api-key\": _LANGSMITH_API_KEY},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
